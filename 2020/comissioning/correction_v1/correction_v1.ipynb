{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set references for v1 tuning using the linear function\n",
    "\n",
    "This notebook is dedicated to apply the linear correction in the neural network output w.r.t the avgmu. \n",
    "\n",
    "**NOTE**: This is an extra study.\n",
    "\n",
    "**NOTE**: Get all models with 2 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.23/01\n",
      "Using all sub packages with ROOT dependence\n"
     ]
    }
   ],
   "source": [
    "from kolmov import crossval_table, get_color_fader, fit_table\n",
    "import saphyra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "etbins = [0.0, 7.0, 10.0, 15.0]\n",
    "etabins = [0.0, 0.8, 1.37, 1.54, 2.37, 2.50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading all tunings:\n",
    "\n",
    "Since I don't have v6 tuning files available, I will reload the production files and get the models for each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_dict(op):\n",
    "    d = {\n",
    "              op+'_pd_ref'    : \"reference/\"+op+\"_cutbased/pd_ref#0\",\n",
    "              op+'_fa_ref'    : \"reference/\"+op+\"_cutbased/fa_ref#0\",\n",
    "              op+'_sp_ref'    : \"reference/\"+op+\"_cutbased/sp_ref\",\n",
    "              op+'_pd_val'    : \"reference/\"+op+\"_cutbased/pd_val#0\",\n",
    "              op+'_fa_val'    : \"reference/\"+op+\"_cutbased/fa_val#0\",\n",
    "              op+'_sp_val'    : \"reference/\"+op+\"_cutbased/sp_val\",\n",
    "              op+'_pd_op'     : \"reference/\"+op+\"_cutbased/pd_op#0\",\n",
    "              op+'_fa_op'     : \"reference/\"+op+\"_cutbased/fa_op#0\",\n",
    "              op+'_sp_op'     : \"reference/\"+op+\"_cutbased/sp_op\",\n",
    "\n",
    "              # Counts\n",
    "              op+'_pd_ref_passed'    : \"reference/\"+op+\"_cutbased/pd_ref#1\",\n",
    "              op+'_fa_ref_passed'    : \"reference/\"+op+\"_cutbased/fa_ref#1\",\n",
    "              op+'_pd_ref_total'     : \"reference/\"+op+\"_cutbased/pd_ref#2\",\n",
    "              op+'_fa_ref_total'     : \"reference/\"+op+\"_cutbased/fa_ref#2\",\n",
    "              op+'_pd_val_passed'    : \"reference/\"+op+\"_cutbased/pd_val#1\",\n",
    "              op+'_fa_val_passed'    : \"reference/\"+op+\"_cutbased/fa_val#1\",\n",
    "              op+'_pd_val_total'     : \"reference/\"+op+\"_cutbased/pd_val#2\",\n",
    "              op+'_fa_val_total'     : \"reference/\"+op+\"_cutbased/fa_val#2\",\n",
    "              op+'_pd_op_passed'     : \"reference/\"+op+\"_cutbased/pd_op#1\",\n",
    "              op+'_fa_op_passed'     : \"reference/\"+op+\"_cutbased/fa_op#1\",\n",
    "              op+'_pd_op_total'      : \"reference/\"+op+\"_cutbased/pd_op#2\",\n",
    "              op+'_fa_op_total'      : \"reference/\"+op+\"_cutbased/fa_op#2\",\n",
    "    }\n",
    "    return d\n",
    "\n",
    "tuned_info = collections.OrderedDict( {\n",
    "              # validation\n",
    "              \"max_sp_val\"      : 'summary/max_sp_val',\n",
    "              \"max_sp_pd_val\"   : 'summary/max_sp_pd_val#0',\n",
    "              \"max_sp_fa_val\"   : 'summary/max_sp_fa_val#0',\n",
    "              # Operation\n",
    "              \"max_sp_op\"       : 'summary/max_sp_op',\n",
    "              \"max_sp_pd_op\"    : 'summary/max_sp_pd_op#0',\n",
    "              \"max_sp_fa_op\"    : 'summary/max_sp_fa_op#0',\n",
    "              } )\n",
    "\n",
    "tuned_info.update(create_op_dict('tight'))\n",
    "tuned_info.update(create_op_dict('medium'))\n",
    "tuned_info.update(create_op_dict('loose'))\n",
    "tuned_info.update(create_op_dict('vloose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-28 14:48:07,715 | Py.crossval_table                       INFO Reading file for v1 tag from /Volumes/castor/tuning_data/Jpsi/v1/r0/*/*/*.gz\n",
      "2021-02-28 14:48:07,715 | Py.crossval_table                       INFO There are 1500 files for this task...\n",
      "2021-02-28 14:48:07,715 | Py.crossval_table                       INFO Filling the table... \n",
      "2021-02-28 14:48:35,994 | Py.crossval_table                       INFO End of fill step, a pandas DataFrame was created...\n"
     ]
    }
   ],
   "source": [
    "cv_v1  = crossval_table( tuned_info, etbins = etbins , etabins = etabins )\n",
    "cv_v1.fill(  '/Volumes/castor/tuning_data/Jpsi/v1/r0/*/*/*.gz', 'v1')\n",
    "best_inits_v1 = cv_v1.filter_inits(\"max_sp_val\")\n",
    "best_sorts_v1 = cv_v1.filter_sorts( best_inits_v1.loc[best_inits_v1.model_idx==0] , 'max_sp_op')\n",
    "best_models = cv_v1.get_best_models(best_sorts_v1, remove_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Linear correction:\n",
    "\n",
    "Here we will set all thresholds to operate as the same pd reference from cut-based using the pileup linear correction strategy. As the classifier efficiency has some \"dependence\" w.r.t the pileup we adopt the linear adjustment to \"fix\" the trigger efficiency. Here we will \"fix\" the neural network threshold w.r.t the pileup. \n",
    "\n",
    "### 2.1) Get all PD/Fas values:\n",
    "\n",
    "Read all reference values from the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all pd/fa from reference file\n",
    "ref_path = '/Volumes/castor/cern_data/files/Jpsiee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM2.bkg.VProbes_EGAM7.GRL_v97/references/'\n",
    "ref_path+= 'data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM2.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.ref.pic.gz'\n",
    "\n",
    "ref_paths = [[ ref_path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(3) ]\n",
    "ref_matrix = [[ {} for eta in range(5)] for et in range(3)]\n",
    "references = ['tight_cutbased', 'medium_cutbased' , 'loose_cutbased', 'vloose_cutbased']\n",
    "from saphyra.core import ReferenceReader\n",
    "for et_bin in range(3):\n",
    "    for eta_bin in range(5):\n",
    "        for name in references:\n",
    "            refObj = ReferenceReader().load(ref_paths[et_bin][eta_bin])\n",
    "            pd = refObj.getSgnPassed(name)/refObj.getSgnTotal(name)\n",
    "            fa = refObj.getBkgPassed(name)/refObj.getBkgTotal(name)\n",
    "            ref_matrix[et_bin][eta_bin][name] = {'pd':pd, 'fa':fa}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Create data generator:\n",
    "\n",
    "Since each tuning models is fed by a different data organization, we need to create a generator to open the data file, prepare the matrix and apply some pre-processing (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator( path ):\n",
    "    def norm1( data ):\n",
    "        norms = np.abs( data.sum(axis=1) )\n",
    "        norms[norms==0] = 1\n",
    "        return data/norms[:,None]\n",
    "    from Gaugi import load\n",
    "    d = load(path)\n",
    "    feature_names = d['features'].tolist()\n",
    "\n",
    "    # How many events?\n",
    "    n = d['data'].shape[0]\n",
    "    \n",
    "    # extract rings\n",
    "    data_rings = norm1(d['data'][:,1:101])\n",
    "    target = d['target']\n",
    "    avgmu = d['data'][:,0]\n",
    "    \n",
    "    return [data_rings], target, avgmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/castor/cern_data/files/Jpsiee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM2.bkg.VProbes_EGAM7.GRL_v97/'\n",
    "path+= 'data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM2.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.npz'\n",
    "paths = [[ path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table class\n",
    "from ROOT import kBlackBody\n",
    "ct  = fit_table( generator, etbins , etabins, 0.001, 1.5, 16.5, 45.5, \n",
    "                 xmin_percentage=0.05, xmax_percentage=99.95, palette=kBlackBody )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Apply linear correction:\n",
    "\n",
    "**NOTE**: Take about 25 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying ATLAS style settings...\n",
      "Fitting... |############################################################| 15/15\n",
      "Fitting... ... finished task in 223.927348s.\n",
      "2021-02-28 18:21:23,623 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-02-28 18:21:44,942 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-02-28 18:21:52,102 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-02-28 18:21:58,731 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-02-28 18:22:05,274 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-02-28 18:22:57,026 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-02-28 18:22:59,987 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-02-28 18:23:04,596 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-02-28 18:23:09,982 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n"
     ]
    }
   ],
   "source": [
    "# Fill it\n",
    "ct.fill(paths, best_models, ref_matrix,\n",
    "        'correction_v1_probes_lhmedium_EGAM2_vetoProbes_EGAM7',\n",
    "         except_these_bins = [(0,2),(0,4), (1,2),(1,4),(2,2),(2,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>et_bin</th>\n",
       "      <th>eta_bin</th>\n",
       "      <th>reference_signal_passed</th>\n",
       "      <th>reference_signal_total</th>\n",
       "      <th>reference_signal_eff</th>\n",
       "      <th>reference_background_passed</th>\n",
       "      <th>reference_background_total</th>\n",
       "      <th>reference_background_eff</th>\n",
       "      <th>signal_passed</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_eff</th>\n",
       "      <th>background_passed</th>\n",
       "      <th>background_total</th>\n",
       "      <th>background_eff</th>\n",
       "      <th>signal_corrected_passed</th>\n",
       "      <th>signal_corrected_total</th>\n",
       "      <th>signal_corrected_eff</th>\n",
       "      <th>background_corrected_passed</th>\n",
       "      <th>background_corrected_total</th>\n",
       "      <th>background_corrected_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27987</td>\n",
       "      <td>28455</td>\n",
       "      <td>0.983553</td>\n",
       "      <td>69344</td>\n",
       "      <td>215903</td>\n",
       "      <td>0.321181</td>\n",
       "      <td>27986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983518</td>\n",
       "      <td>29118</td>\n",
       "      <td>215903</td>\n",
       "      <td>0.134866</td>\n",
       "      <td>27974</td>\n",
       "      <td>28455</td>\n",
       "      <td>0.983096</td>\n",
       "      <td>31361</td>\n",
       "      <td>215903</td>\n",
       "      <td>0.145255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27987</td>\n",
       "      <td>28455</td>\n",
       "      <td>0.983553</td>\n",
       "      <td>69344</td>\n",
       "      <td>215903</td>\n",
       "      <td>0.321181</td>\n",
       "      <td>27986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983518</td>\n",
       "      <td>29118</td>\n",
       "      <td>215903</td>\n",
       "      <td>0.134866</td>\n",
       "      <td>27974</td>\n",
       "      <td>28455</td>\n",
       "      <td>0.983096</td>\n",
       "      <td>31361</td>\n",
       "      <td>215903</td>\n",
       "      <td>0.145255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27827</td>\n",
       "      <td>28455</td>\n",
       "      <td>0.977930</td>\n",
       "      <td>64940</td>\n",
       "      <td>215903</td>\n",
       "      <td>0.300783</td>\n",
       "      <td>27826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977895</td>\n",
       "      <td>23898</td>\n",
       "      <td>215903</td>\n",
       "      <td>0.110689</td>\n",
       "      <td>27829</td>\n",
       "      <td>28455</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>25495</td>\n",
       "      <td>215903</td>\n",
       "      <td>0.118085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vloose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28149</td>\n",
       "      <td>28455</td>\n",
       "      <td>0.989246</td>\n",
       "      <td>72834</td>\n",
       "      <td>215903</td>\n",
       "      <td>0.337346</td>\n",
       "      <td>28148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989211</td>\n",
       "      <td>36929</td>\n",
       "      <td>215903</td>\n",
       "      <td>0.171044</td>\n",
       "      <td>28154</td>\n",
       "      <td>28455</td>\n",
       "      <td>0.989422</td>\n",
       "      <td>39303</td>\n",
       "      <td>215903</td>\n",
       "      <td>0.182040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8363</td>\n",
       "      <td>8736</td>\n",
       "      <td>0.957303</td>\n",
       "      <td>86022</td>\n",
       "      <td>179082</td>\n",
       "      <td>0.480350</td>\n",
       "      <td>8363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957303</td>\n",
       "      <td>20363</td>\n",
       "      <td>179082</td>\n",
       "      <td>0.113708</td>\n",
       "      <td>8365</td>\n",
       "      <td>8736</td>\n",
       "      <td>0.957532</td>\n",
       "      <td>21825</td>\n",
       "      <td>179082</td>\n",
       "      <td>0.121872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  et_bin  eta_bin  reference_signal_passed  \\\n",
       "0   tight_cutbased       0        0                    27987   \n",
       "1  medium_cutbased       0        0                    27987   \n",
       "2   loose_cutbased       0        0                    27827   \n",
       "3  vloose_cutbased       0        0                    28149   \n",
       "4   tight_cutbased       0        1                     8363   \n",
       "\n",
       "   reference_signal_total  reference_signal_eff  reference_background_passed  \\\n",
       "0                   28455              0.983553                        69344   \n",
       "1                   28455              0.983553                        69344   \n",
       "2                   28455              0.977930                        64940   \n",
       "3                   28455              0.989246                        72834   \n",
       "4                    8736              0.957303                        86022   \n",
       "\n",
       "   reference_background_total  reference_background_eff  signal_passed  ...  \\\n",
       "0                      215903                  0.321181          27986  ...   \n",
       "1                      215903                  0.321181          27986  ...   \n",
       "2                      215903                  0.300783          27826  ...   \n",
       "3                      215903                  0.337346          28148  ...   \n",
       "4                      179082                  0.480350           8363  ...   \n",
       "\n",
       "   signal_eff  background_passed  background_total  background_eff  \\\n",
       "0    0.983518              29118            215903        0.134866   \n",
       "1    0.983518              29118            215903        0.134866   \n",
       "2    0.977895              23898            215903        0.110689   \n",
       "3    0.989211              36929            215903        0.171044   \n",
       "4    0.957303              20363            179082        0.113708   \n",
       "\n",
       "   signal_corrected_passed  signal_corrected_total  signal_corrected_eff  \\\n",
       "0                    27974                   28455              0.983096   \n",
       "1                    27974                   28455              0.983096   \n",
       "2                    27829                   28455              0.978000   \n",
       "3                    28154                   28455              0.989422   \n",
       "4                     8365                    8736              0.957532   \n",
       "\n",
       "   background_corrected_passed  background_corrected_total  \\\n",
       "0                        31361                      215903   \n",
       "1                        31361                      215903   \n",
       "2                        25495                      215903   \n",
       "3                        39303                      215903   \n",
       "4                        21825                      179082   \n",
       "\n",
       "   background_corrected_eff  \n",
       "0                  0.145255  \n",
       "1                  0.145255  \n",
       "2                  0.118085  \n",
       "3                  0.182040  \n",
       "4                  0.121872  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.table().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Create beamer report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-28 18:23:20,113 | Py.BeamerTexReportTemplate1             INFO Started creating beamer file correction_v1_data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetoProbes.pdf latex code...\n"
     ]
    }
   ],
   "source": [
    "ct.dump_beamer_table(ct.table(), best_models, 'data17_13TeV v1 tuning (Jpsiee)', \n",
    "                     'correction_v1_data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetoProbes.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export tunings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronTight.et2_eta4.onnx\n",
      "2021-02-28 18:24:34,108 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerTightTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronMedium.et2_eta4.onnx\n",
      "2021-02-28 18:25:49,646 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerMediumTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronLoose.et2_eta4.onnx\n",
      "2021-02-28 18:26:46,006 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerLooseTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electronVeryLoose.et2_eta4.onnx\n",
      "2021-02-28 18:27:36,096 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerVeryLooseTriggerConfig.conf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 18:23:38.163825: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:23:38.192629: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffe1526f6e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:23:38.192649: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:23:42.048984: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:23:42.066075: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9d8ac67590 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:23:42.066100: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:23:45.446428: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:23:45.467307: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffa22df7370 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:23:45.467323: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:23:49.156955: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:23:49.181568: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffa5740c440 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:23:49.181592: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:23:52.795420: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:23:52.809913: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd5ee8f9160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:23:52.809930: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:23:56.221508: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:23:56.244511: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe0e6524200 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:23:56.244537: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:23:59.678532: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:23:59.696135: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff4320b7d20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:23:59.696161: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:24:03.232551: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:24:03.253213: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbee850df50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:24:03.253229: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:24:06.822496: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:24:06.836094: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe4a44aa570 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:24:06.836109: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:24:10.287171: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:24:10.306725: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f90ef897ea0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:24:10.306742: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:24:13.855554: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:24:13.885537: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f88a0e06600 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:24:13.885557: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:24:18.932424: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:24:18.975919: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf41d43cc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:24:18.975975: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:24:23.344806: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:24:23.364176: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe7e6bd58d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:24:23.364219: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:24:28.844001: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:24:28.919149: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb713cf500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:24:28.919180: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:24:33.464970: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:24:33.505700: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe841d7cfb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:24:33.505729: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:24:37.848919: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:24:37.862560: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7feb09db78c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:24:37.862576: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:24:41.815980: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:24:41.829456: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb9a34b1250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:24:41.829472: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:24:46.157977: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:24:46.171713: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fab40d03e10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:24:46.171728: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:24:50.975426: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:24:50.990096: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd38fc60160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:24:50.990114: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:24:56.626373: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:24:56.640599: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f867db6eca0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:24:56.640614: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:25:02.084957: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:25:02.103909: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd9414d4900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:25:02.103948: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:25:07.931248: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:25:07.966901: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffa6e64d5f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:25:07.966919: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:25:12.890769: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:25:12.904680: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9ac8b8e3c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:25:12.904701: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:25:18.236182: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:25:18.295371: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f960d368090 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:25:18.295489: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:25:22.890466: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:25:22.904517: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8799399720 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:25:22.904533: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:25:28.378332: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:25:28.409056: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f854d625bf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:25:28.409117: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:25:33.581846: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:25:33.614109: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8a1ad035f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:25:33.614133: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:25:39.960305: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:25:39.973760: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a00d3c300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:25:39.973776: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:25:44.833696: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:25:44.847153: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb37fd60a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:25:44.847168: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:25:49.157472: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:25:49.175104: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe024d837b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:25:49.175122: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:25:52.863370: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:25:52.876960: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc7ef4f14e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:25:52.876974: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:25:57.623635: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:25:57.637815: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8334d0b9a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:25:57.637830: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:01.760300: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:01.776265: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb05cde2b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:01.776283: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:05.957382: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:05.999800: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa4dba52070 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:05.999817: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:11.365303: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:11.382533: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbea8b74a60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:11.382551: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:15.083097: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:15.097101: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc548c34830 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:15.097117: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:18.581519: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:18.601905: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa210d55c00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:18.601926: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:22.208848: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:22.234634: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe0cb447300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:22.234661: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:25.432740: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:25.457006: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbc372e00f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:25.457024: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:29.345798: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:29.359708: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb462d06b90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:29.359730: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:32.499149: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:32.520419: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe327428560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:32.520477: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:35.891617: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:35.905215: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a55f6ab70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:35.905233: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:39.010552: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:39.031231: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc0e3c4b700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:39.031250: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:42.277493: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:42.291274: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9eb54da520 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:42.291289: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:45.669395: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:45.683191: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb420d4c5d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:45.683207: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:48.694472: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:48.713686: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd07a731b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:48.713709: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:52.088314: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:52.102497: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd92ea811c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:52.102524: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:55.600772: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:55.615949: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc62487c500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:55.615981: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:26:58.981611: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:26:59.004812: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb2c4ae5e60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:26:59.004828: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:27:02.390158: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:27:02.404132: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9753491ac0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:27:02.404147: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:27:05.874101: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:27:05.893550: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f99dbab9aa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:27:05.893567: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:27:09.273414: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:27:09.294736: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fac72442b10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:27:09.294752: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:27:12.422753: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:27:12.437036: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fef79de6e90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:27:12.437055: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:27:15.676174: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:27:15.695939: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fde4c252210 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:27:15.695965: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:27:18.876980: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:27:18.893645: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff878c42870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:27:18.893711: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:27:22.157474: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:27:22.173762: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbe1b5bcea0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:27:22.173782: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:27:25.603633: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:27:25.617839: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbebf48e3b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:27:25.617856: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:27:28.873019: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:27:28.892446: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa652bd8990 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:27:28.892474: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:27:32.166935: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:27:32.180125: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faaa46ed030 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:27:32.180141: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n",
      "2021-02-28 18:27:35.624690: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-28 18:27:35.649534: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb755053a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-02-28 18:27:35.649550: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 10 -> 5\n",
      "The maximum opset needed by this model is only 9.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name_format = 'data17_13TeV_EGAM2_probes_lhmedium_EGAM7_vetolhvloose.model_v1.electron{op}.et%d_eta%d'\n",
    "config_name_format = 'ElectronRinger{op}TriggerConfig.conf'\n",
    "for idx, op in enumerate(['Tight','Medium','Loose','VeryLoose']):\n",
    "    ct.export(best_models, \n",
    "              model_name_format.format(op=op), \n",
    "              config_name_format.format(op=op), \n",
    "              references[idx], \n",
    "              to_onnx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
